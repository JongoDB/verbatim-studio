name: Build Electron App

on:
  push:
    tags:
      - 'v*'
  pull_request:
    branches: [main]
    paths:
      - 'apps/electron/**'
      - 'packages/frontend/**'
      - 'packages/backend/**'
      - 'scripts/**'
      - '.github/workflows/build-electron.yml'
  workflow_dispatch:

jobs:
  build:
    strategy:
      fail-fast: false
      matrix:
        include:
          - os: macos-14
            arch: arm64
            platform: darwin
          - os: windows-latest
            arch: x64
            platform: win32

    runs-on: ${{ matrix.os }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9

      - name: Get pnpm store directory
        shell: bash
        run: |
          echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_ENV

      - name: Setup pnpm cache
        uses: actions/cache@v4
        with:
          path: ${{ env.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      - name: Install CUDA Toolkit
        if: matrix.platform == 'win32'
        uses: Jimver/cuda-toolkit@v0.2.30
        id: cuda-toolkit
        with:
          cuda: '12.6.3'
          method: 'network'
          sub-packages: '["cudart", "cublas"]'

      # Cache Python standalone + dependencies to speed up builds
      - name: Cache Python environment
        uses: actions/cache@v4
        id: python-cache
        with:
          path: build/python-standalone
          key: ${{ runner.os }}-${{ matrix.arch }}-python-ml-v5-${{ hashFiles('scripts/requirements-core.txt', 'scripts/requirements-ml.txt', 'scripts/requirements-ml-windows.txt', 'scripts/install-bundled-deps.sh') }}

      - name: Install dependencies
        run: pnpm install

      - name: Download Python standalone
        if: steps.python-cache.outputs.cache-hit != 'true'
        shell: bash
        run: ./scripts/download-python-standalone.sh ${{ matrix.arch }}

      - name: Install Python dependencies (core + ML)
        if: steps.python-cache.outputs.cache-hit != 'true'
        shell: bash
        run: |
          echo "Installing all Python dependencies (this may take a while)..."
          ./scripts/install-bundled-deps.sh
        env:
          # Increase pip timeout for large packages
          PIP_DEFAULT_TIMEOUT: 300

      - name: Verify Python dependencies (strict version check)
        shell: bash
        run: |
          if [ "${{ matrix.platform }}" = "win32" ]; then
            PYTHON_BIN="build/python-standalone/python-windows-x64/python.exe"
            SITE_PACKAGES="build/python-standalone/python-windows-x64/Lib/site-packages"
          else
            PYTHON_BIN="build/python-standalone/python-macos-arm64/bin/python3"
            SITE_PACKAGES="build/python-standalone/python-macos-arm64/lib/python3.12/site-packages"
          fi
          echo "=== Installed ML packages ==="
          "$PYTHON_BIN" -m pip list --path "$SITE_PACKAGES" | grep -E "torch|whisper|pyannote|mlx|transformers|huggingface|sentence|numpy" || true
          echo ""
          echo "=== STRICT Version Verification ==="

          PACKAGE_LIST=$("$PYTHON_BIN" -m pip list --path "$SITE_PACKAGES" --format=freeze 2>/dev/null)
          FAILED=0

          check_installed() {
            local pkg=$1
            local pattern=$(echo "$pkg" | sed 's/-/_/g; s/\./_/g')
            local version=$(echo "$PACKAGE_LIST" | grep -i "^${pattern}==" | cut -d'=' -f3 | head -1)
            if [ -z "$version" ]; then
              version=$(echo "$PACKAGE_LIST" | grep -i "^${pkg}==" | cut -d'=' -f3 | head -1)
            fi
            if [ -n "$version" ]; then
              echo "✓ $pkg: $version"
            else
              echo "✗ $pkg: NOT_INSTALLED"
              return 1
            fi
          }

          check_version() {
            local pkg=$1
            local expected=$2
            local actual=$(echo "$PACKAGE_LIST" | grep -i "^${pkg}==" | cut -d'=' -f3 | head -1)
            if [ -z "$actual" ]; then
              local pkg_underscore=$(echo "$pkg" | sed 's/-/_/g; s/\./_/g')
              actual=$(echo "$PACKAGE_LIST" | grep -i "^${pkg_underscore}==" | cut -d'=' -f3 | head -1)
            fi
            if [ -z "$actual" ]; then actual="NOT_INSTALLED"; fi
            if [ "$actual" = "$expected" ]; then
              echo "✓ $pkg: $actual"
            else
              echo "✗ $pkg: $actual (expected $expected)"
              return 1
            fi
          }

          # Core document processing packages
          check_installed "PyMuPDF" || FAILED=1
          check_installed "python-docx" || FAILED=1
          check_installed "openpyxl" || FAILED=1
          check_installed "python-pptx" || FAILED=1

          # ML packages (verify exact versions)
          check_version "torch" "2.8.0" || FAILED=1
          check_version "torchaudio" "2.8.0" || FAILED=1
          check_version "huggingface-hub" "0.36.1" || FAILED=1
          check_version "transformers" "4.48.0" || FAILED=1
          check_version "numpy" "2.0.2" || FAILED=1
          check_version "whisperx" "3.3.4" || FAILED=1

          # pyannote — bundled on all platforms
          check_version "pyannote.audio" "3.3.2" || FAILED=1
          check_version "pyannote.core" "5.0.0" || FAILED=1
          check_version "pyannote.database" "5.1.3" || FAILED=1
          check_version "pyannote.pipeline" "3.0.1" || FAILED=1
          check_version "pyannote.metrics" "3.2.1" || FAILED=1

          # Platform-specific checks
          if [ "${{ matrix.platform }}" = "darwin" ]; then
            check_version "mlx-whisper" "0.4.3" || FAILED=1
          fi

          echo ""
          if [ $FAILED -eq 1 ]; then
            echo "=== BUILD FAILED: Version mismatch detected! ==="
            echo "The installed package versions do not match the required versions."
            echo "This will cause runtime errors. Check pip dependency resolution."
            exit 1
          fi
          echo "=== All versions verified ✓ ==="

      # Cache whisper models to avoid re-downloading every build (~145MB for whisper-base)
      - name: Cache Whisper models
        uses: actions/cache@v4
        id: whisper-cache
        with:
          path: build/resources/whisper-models
          key: whisper-models-v3-${{ runner.os }}-${{ hashFiles('scripts/prepare-whisper-models.sh', 'scripts/prepare-whisper-models-windows.sh') }}

      - name: Prepare Whisper models for bundling
        if: matrix.platform == 'darwin' && steps.whisper-cache.outputs.cache-hit != 'true'
        shell: bash
        run: |
          echo "Downloading Whisper models for offline transcription..."
          ./scripts/prepare-whisper-models.sh
        env:
          HF_HUB_DISABLE_PROGRESS_BARS: 1

      - name: Prepare Whisper models for bundling (Windows)
        if: matrix.platform == 'win32' && steps.whisper-cache.outputs.cache-hit != 'true'
        shell: bash
        run: |
          echo "Downloading CTranslate2 Whisper models..."
          ./scripts/prepare-whisper-models-windows.sh
        env:
          HF_HUB_DISABLE_PROGRESS_BARS: 1

      - name: Verify Whisper models are present
        shell: bash
        run: |
          if [ "${{ matrix.platform }}" = "win32" ]; then
            WHISPER_DIR="build/resources/whisper-models/huggingface/hub/models--Systran--faster-whisper-base"
          else
            WHISPER_DIR="build/resources/whisper-models/huggingface/hub/models--mlx-community--whisper-base-mlx"
          fi
          if [ ! -d "$WHISPER_DIR" ]; then
            echo "ERROR: Whisper models directory not found at $WHISPER_DIR"
            echo "Contents of build/resources/whisper-models:"
            find build/resources/whisper-models -type f 2>/dev/null | head -20 || echo "(empty)"
            exit 1
          fi
          SNAPSHOTS_DIR="$WHISPER_DIR/snapshots"
          if [ ! -d "$SNAPSHOTS_DIR" ] || [ -z "$(ls -A $SNAPSHOTS_DIR 2>/dev/null)" ]; then
            echo "ERROR: Whisper model snapshots directory is empty or missing"
            exit 1
          fi
          echo "Whisper models verified:"
          du -sh "$WHISPER_DIR"
          ls -la "$SNAPSHOTS_DIR"

      # Cache embedding models to avoid re-downloading every build (~550MB for nomic-embed-text)
      - name: Cache Embedding models
        uses: actions/cache@v4
        id: embedding-cache
        with:
          path: build/resources/embedding-models
          key: embedding-models-v2-${{ runner.os }}-${{ hashFiles('scripts/prepare-embedding-models.sh') }}

      - name: Prepare Embedding models for bundling
        if: steps.embedding-cache.outputs.cache-hit != 'true'
        shell: bash
        run: |
          echo "Downloading embedding model for semantic search..."
          ./scripts/prepare-embedding-models.sh
        env:
          HF_HUB_DISABLE_PROGRESS_BARS: 1

      - name: Verify Embedding models are present
        shell: bash
        run: |
          EMBED_DIR="build/resources/embedding-models/huggingface/hub/models--nomic-ai--nomic-embed-text-v1.5"
          if [ ! -d "$EMBED_DIR" ]; then
            echo "ERROR: Embedding model directory not found at $EMBED_DIR"
            exit 1
          fi
          SNAPSHOTS_DIR="$EMBED_DIR/snapshots"
          if [ ! -d "$SNAPSHOTS_DIR" ] || [ -z "$(ls -A $SNAPSHOTS_DIR 2>/dev/null)" ]; then
            echo "ERROR: Embedding model snapshots directory is empty or missing"
            exit 1
          fi
          echo "Embedding model verified:"
          du -sh "$EMBED_DIR"

      # Cache FFmpeg binaries to avoid re-downloading every build (~50MB)
      - name: Cache FFmpeg
        uses: actions/cache@v4
        id: ffmpeg-cache
        with:
          path: build/resources/ffmpeg
          key: ffmpeg-v1-${{ runner.os }}-${{ matrix.arch }}-${{ hashFiles('scripts/download-ffmpeg.sh') }}

      - name: Prepare Electron resources
        shell: bash
        run: ./scripts/prepare-electron-resources.sh

      - name: Bundle CUDA runtime libraries
        if: matrix.platform == 'win32'
        shell: bash
        run: ./scripts/bundle-cuda-libs.sh

      - name: Strip Python environment (reduce bundle size)
        if: matrix.platform == 'win32'
        shell: bash
        run: |
          SITE_PACKAGES="build/python-standalone/python-windows-x64/Lib/site-packages"
          echo "=== Before cleanup ==="
          du -sh "$SITE_PACKAGES" || true

          # ---------------------------------------------------------------
          # 1. Remove torchvision entirely (~500MB-1GB)
          #    Only needed by optional OCR feature, which installs on-demand
          # ---------------------------------------------------------------
          rm -rf "$SITE_PACKAGES/torchvision"
          rm -rf "$SITE_PACKAGES/torchvision-"*.dist-info

          # ---------------------------------------------------------------
          # 2. Remove nvidia-* pip packages
          #    CUDA DLLs are now in build/resources/cuda/ via bundle-cuda-libs.sh
          #    No need to keep full nvidia packages in Python env
          # ---------------------------------------------------------------
          rm -rf "$SITE_PACKAGES/nvidia"
          rm -rf "$SITE_PACKAGES/nvidia_"*.dist-info

          # ---------------------------------------------------------------
          # 3. Strip speechbrain/lightning bloat from pyannote dependency tree
          # ---------------------------------------------------------------
          rm -rf "$SITE_PACKAGES/speechbrain/tests"
          rm -rf "$SITE_PACKAGES/speechbrain/recipes"
          rm -rf "$SITE_PACKAGES/speechbrain/templates"
          rm -rf "$SITE_PACKAGES/speechbrain/benchmarks"
          rm -rf "$SITE_PACKAGES/lightning/fabric/test_utilities"
          rm -rf "$SITE_PACKAGES/lightning/pytorch/test_utilities"
          rm -rf "$SITE_PACKAGES/pytorch_lightning/demos"

          # ---------------------------------------------------------------
          # 4. Remove PyTorch development/build files
          # ---------------------------------------------------------------
          rm -rf "$SITE_PACKAGES/torch/include"
          rm -rf "$SITE_PACKAGES/torch/share"
          rm -rf "$SITE_PACKAGES/torch/lib/cmake"
          find "$SITE_PACKAGES/torch" -name "*.lib" -delete 2>/dev/null || true
          find "$SITE_PACKAGES/torch" -name "*.pdb" -delete 2>/dev/null || true

          # ---------------------------------------------------------------
          # 5. Remove PyTorch test scripts only
          # ---------------------------------------------------------------
          rm -rf "$SITE_PACKAGES/torch/test"

          # ---------------------------------------------------------------
          # 6. General cleanup
          # ---------------------------------------------------------------
          find "$SITE_PACKAGES" -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true

          echo "=== After cleanup ==="
          du -sh "$SITE_PACKAGES" || true
          echo "=== Largest remaining directories ==="
          du -sh "$SITE_PACKAGES"/torch/lib 2>/dev/null || true
          du -sh "$SITE_PACKAGES"/torch 2>/dev/null || true
          du -sh "$SITE_PACKAGES"/torchaudio 2>/dev/null || true

      - name: Verify imports after stripping
        if: matrix.platform == 'win32'
        shell: bash
        run: |
          PYTHON_BIN="build/python-standalone/python-windows-x64/python.exe"
          SITE_PACKAGES="build/python-standalone/python-windows-x64/Lib/site-packages"
          echo "=== Verifying imports after strip ==="
          "$PYTHON_BIN" -c "
          import torch
          print('PyTorch version:', torch.__version__)
          import torchaudio
          print('torchaudio version:', torchaudio.__version__)
          import ctranslate2
          print('CTranslate2 version:', ctranslate2.__version__)
          print('CTranslate2 CUDA devices:', ctranslate2.get_cuda_device_count())
          import pyannote.audio
          print('pyannote.audio version:', pyannote.audio.__version__)
          import speechbrain
          print('speechbrain version:', speechbrain.__version__)
          print('All imports OK')
          "

      - name: Bundle Size Check
        if: matrix.platform == 'win32'
        shell: bash
        run: |
          RESOURCES_DIR="build/resources"
          if [ -d "$RESOURCES_DIR" ]; then
            SIZE_MB=$(du -sm "$RESOURCES_DIR" | cut -f1)
            echo "Resources directory size: ${SIZE_MB}MB"
            if [ "$SIZE_MB" -gt 1800 ]; then
              echo "::warning::Resources size ${SIZE_MB}MB exceeds 1800MB safety threshold for NSIS 2GB limit"
            else
              echo "Resources size ${SIZE_MB}MB is within 1800MB safety threshold"
            fi
          else
            echo "Resources directory not found (may not be assembled yet)"
          fi

      - name: Update version from git tag
        shell: bash
        run: ./scripts/update-version.sh

      - name: Build frontend
        run: pnpm --filter @verbatim/frontend build:ci

      - name: Build Electron
        run: pnpm --filter @verbatim/electron build

      - name: Package Electron app
        run: |
          if [ "${{ matrix.platform }}" = "darwin" ]; then
            # Skip signing on macOS (add CSC_LINK secret to enable)
            pnpm --filter @verbatim/electron exec electron-builder --publish never --config.mac.identity=null
          else
            pnpm --filter @verbatim/electron exec electron-builder --publish never
          fi
        shell: bash
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          # macOS code signing (when secrets are set)
          CSC_LINK: ${{ secrets.MAC_CERTS }}
          CSC_KEY_PASSWORD: ${{ secrets.MAC_CERTS_PASSWORD }}
          APPLE_ID: ${{ secrets.APPLE_ID }}
          APPLE_APP_SPECIFIC_PASSWORD: ${{ secrets.APPLE_APP_SPECIFIC_PASSWORD }}
          APPLE_TEAM_ID: ${{ secrets.APPLE_TEAM_ID }}
          # Windows code signing
          WIN_CSC_LINK: ${{ secrets.WIN_CSC_LINK }}
          WIN_CSC_KEY_PASSWORD: ${{ secrets.WIN_CSC_KEY_PASSWORD }}

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: verbatim-studio-${{ matrix.platform }}-${{ matrix.arch }}
          path: |
            dist/*.dmg
            dist/*.exe
          if-no-files-found: error

  release:
    needs: build
    if: startsWith(github.ref, 'refs/tags/')
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      - name: Create Release
        uses: softprops/action-gh-release@v2
        with:
          files: artifacts/**/*
          generate_release_notes: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
