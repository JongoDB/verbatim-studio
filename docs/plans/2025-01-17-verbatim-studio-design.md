# Verbatim Studio - Design Document

**Version:** 1.0
**Date:** January 17, 2025
**Status:** Approved for implementation

---

## Executive Summary

**Product**: Verbatim Studio - Privacy-first transcription for professionals

**Initial Release**: macOS (Apple Silicon) native application with full offline AI capabilities

**Core Value Proposition**: Legal, medical, and government professionals get enterprise-grade transcription that never sends data off their machine. Real-time and batch transcription, speaker identification, AI summarization - all running locally with GPU acceleration.

**Target Platform**: macOS ARM64 (Apple Silicon) with Metal GPU acceleration. Windows and Linux support planned for future releases.

---

## Key Decisions

| Aspect | Decision |
|--------|----------|
| Priority | Basic mode (single-user, local) first |
| Desktop Framework | Electron |
| Frontend | React + shadcn/ui + Tailwind |
| Backend | FastAPI (Python) |
| ASR (Real-time) | whisper.cpp with Metal GPU |
| ASR (Batch) | WhisperX via embedded Python |
| LLM | llama.cpp (direct integration, not Ollama) |
| Diarization | Pyannote (bundled at build time) |
| Database | SQLite |
| Python Runtime | Embedded via python-build-standalone |
| Models | Bundle whisper-tiny + pyannote; download larger models at install |
| Codebase | Clean rewrite using existing spec as reference |

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Electron Shell                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚              React + shadcn/ui Frontend                  â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                        â”‚ HTTP (localhost)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚              FastAPI Backend (Python)                    â”‚â”‚
â”‚  â”‚         SQLite â”‚ Threading Queue â”‚ File Storage          â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                        â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ whisper  â”‚    WhisperX +       â”‚ llama    â”‚              â”‚
â”‚  â”‚ .cpp     â”‚    Pyannote         â”‚ .cpp     â”‚              â”‚
â”‚  â”‚ (native) â”‚    (Python)         â”‚ (native) â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Component Architecture

### Electron Main Process
- App lifecycle management
- Window creation and management
- IPC handlers for native features (file dialogs, notifications, system tray)
- Backend process spawning and health monitoring
- Model download manager
- Auto-updater

### FastAPI Backend (Python subprocess)
- Runs on `localhost:8000` (configurable)
- REST API for all frontend operations
- SQLite database (stored in `~/Library/Application Support/Verbatim Studio/`)
- File storage for recordings and exports
- Job queue via Python threading (ThreadPoolExecutor)
- Coordinates calls to ML services

### ML Services

| Service | Runtime | Purpose | GPU |
|---------|---------|---------|-----|
| whisper.cpp | Native binary | Real-time transcription | Metal |
| WhisperX | Embedded Python | Batch transcription | Metal via MLX or CPU |
| Pyannote | Embedded Python | Speaker diarization | CPU |
| llama.cpp | Native binary | Summarization, chat, embeddings | Metal |

### Data Storage

```
~/Library/Application Support/Verbatim Studio/
â”œâ”€â”€ verbatim.db          # SQLite database
â”œâ”€â”€ config.json          # App configuration
â”œâ”€â”€ media/               # Uploaded recordings
â”œâ”€â”€ exports/             # Generated documents
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ whisper/         # Whisper models (ggml format)
â”‚   â”œâ”€â”€ llm/             # LLM models (gguf format)
â”‚   â””â”€â”€ pyannote/        # Diarization models
â””â”€â”€ logs/
```

---

## Core Data Flows

### Flow 1: Batch Transcription (File Upload)

```
User drops audio file
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Electron IPC    â”‚ â”€â”€â”€ Native file dialog (optional)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend        â”‚ â”€â”€â”€ POST /api/recordings/upload
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FastAPI         â”‚ â”€â”€â”€ Save to ~/media/, create DB record
â”‚                 â”‚ â”€â”€â”€ Queue transcription job
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Thread Worker   â”‚ â”€â”€â”€ WhisperX transcribe (high accuracy)
â”‚                 â”‚ â”€â”€â”€ Pyannote diarize (speaker labels)
â”‚                 â”‚ â”€â”€â”€ Merge results, save to DB
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend        â”‚ â”€â”€â”€ Poll or WebSocket for status
â”‚                 â”‚ â”€â”€â”€ Display transcript with speakers
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flow 2: Real-Time Transcription (Microphone)

```
User clicks "Start Recording"
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend        â”‚ â”€â”€â”€ Request microphone permission
â”‚                 â”‚ â”€â”€â”€ WebSocket to /ws/transcribe
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FastAPI WS      â”‚ â”€â”€â”€ Audio chunks arrive (~100ms intervals)
â”‚                 â”‚ â”€â”€â”€ Buffer to whisper.cpp process
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ whisper.cpp     â”‚ â”€â”€â”€ Streaming inference (Metal GPU)
â”‚                 â”‚ â”€â”€â”€ Return partial transcripts
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend        â”‚ â”€â”€â”€ Live text display
â”‚                 â”‚ â”€â”€â”€ On stop: save full recording
â”‚                 â”‚ â”€â”€â”€ Optional: re-process with WhisperX for accuracy
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flow 3: AI Summarization

```
User clicks "Summarize" on transcript
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend        â”‚ â”€â”€â”€ POST /api/ai/summarize
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FastAPI         â”‚ â”€â”€â”€ Load transcript text
â”‚                 â”‚ â”€â”€â”€ Call llama.cpp with prompt
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ llama.cpp       â”‚ â”€â”€â”€ Generate summary (Metal GPU)
â”‚                 â”‚ â”€â”€â”€ Stream tokens back
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend        â”‚ â”€â”€â”€ Display streaming summary
â”‚                 â”‚ â”€â”€â”€ Save to transcript metadata
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Native Binary Integration

### Sidecar Server Pattern

whisper.cpp and llama.cpp run as local HTTP servers:

```
Verbatim Studio.app/
â””â”€â”€ Contents/
    â””â”€â”€ Resources/
        â””â”€â”€ bin/
            â”œâ”€â”€ whisper-server      # whisper.cpp HTTP server mode
            â”œâ”€â”€ llama-server        # llama.cpp HTTP server mode
            â””â”€â”€ models/
                â””â”€â”€ whisper-tiny.bin  # Bundled base model
```

### Why Sidecar Servers

| Approach | Pros | Cons |
|----------|------|------|
| Sidecar HTTP | Process isolation, crash recovery, same API as remote services | Extra port, slight latency |
| FFI (ctypes/cffi) | Direct calls, no network | Crashes take down Python, complex bindings |

Benefits:
1. **Crash isolation** - If whisper.cpp crashes, backend stays up
2. **Same interface as Enterprise** - Remote services use HTTP too
3. **Easier debugging** - Can test servers independently
4. **Already supported** - whisper.cpp and llama.cpp have server modes built-in

### Service Implementation

```python
# packages/backend/services/whisper_service.py

class WhisperService:
    def __init__(self):
        self.process = None
        self.port = 8081

    async def start(self, model_path: str):
        self.process = subprocess.Popen([
            get_resource_path("bin/whisper-server"),
            "--model", model_path,
            "--port", str(self.port),
            "--host", "127.0.0.1"
        ])
        await self._wait_for_ready()

    async def transcribe_stream(self, audio_stream):
        async with websockets.connect(f"ws://127.0.0.1:{self.port}/inference") as ws:
            async for chunk in audio_stream:
                await ws.send(chunk)
                result = await ws.recv()
                yield json.loads(result)
```

---

## Python Runtime Bundling

### Structure

```
Verbatim Studio.app/
â””â”€â”€ Contents/
    â””â”€â”€ Resources/
        â””â”€â”€ python/
            â”œâ”€â”€ bin/
            â”‚   â””â”€â”€ python3.11           # Standalone Python
            â”œâ”€â”€ lib/
            â”‚   â””â”€â”€ python3.11/
            â”‚       â””â”€â”€ site-packages/   # All dependencies
            â””â”€â”€ backend/                 # FastAPI code
                â”œâ”€â”€ api/
                â”œâ”€â”€ services/
                â””â”€â”€ main.py
```

### Build Process

```bash
# 1. Download standalone Python
curl -LO https://github.com/indygreg/python-build-standalone/releases/download/.../cpython-3.11-aarch64-apple-darwin-install_only.tar.gz
tar -xzf cpython-3.11-*.tar.gz -C build/python

# 2. Install dependencies
build/python/bin/pip install \
    fastapi uvicorn[standard] \
    whisperx \
    pyannote.audio \
    torch torchvision torchaudio \
    sqlalchemy aiosqlite \
    python-multipart httpx

# 3. Copy backend source
cp -r backend/ build/python/backend/

# 4. Trim unnecessary files
find build/python -name "*.pyc" -delete
find build/python -name "__pycache__" -delete
rm -rf build/python/lib/python3.11/test
```

### Size Estimates

| Component | Size |
|-----------|------|
| Python standalone | ~50 MB |
| PyTorch (CPU/MPS) | ~150 MB |
| WhisperX + deps | ~30 MB |
| Pyannote + deps | ~20 MB |
| FastAPI + deps | ~10 MB |
| **Total Python bundle** | **~260 MB** |

### Startup Sequence

```typescript
// electron/src/main/backend.ts

async function startBackend(): Promise<void> {
  const pythonPath = path.join(
    process.resourcesPath,
    'python/bin/python3.11'
  );
  const backendPath = path.join(
    process.resourcesPath,
    'python/backend'
  );

  backendProcess = spawn(pythonPath, [
    '-m', 'uvicorn',
    'main:app',
    '--host', '127.0.0.1',
    '--port', '8000'
  ], {
    cwd: backendPath,
    env: {
      ...process.env,
      VERBATIM_MODE: 'basic',
      VERBATIM_DATA_DIR: app.getPath('userData'),
    }
  });

  await waitForHealthy('http://127.0.0.1:8000/health');
}
```

---

## Model Management

### Model Distribution Strategy

| Model Type | Distribution | Rationale |
|------------|--------------|-----------|
| Whisper (tiny) | Bundled | Immediate basic functionality |
| Whisper (base/large/turbo) | Optional at install | User chooses quality tier |
| Pyannote | Bundled | No HF token friction, core feature |
| LLMs | Post-install download | Not blocking core transcription |

### Model Catalog

```typescript
const MODEL_CATALOG = {
  whisper: [
    { id: 'tiny', size: '75MB', quality: 'Draft', bundled: true },
    { id: 'base', size: '142MB', quality: 'Basic', bundled: false },
    { id: 'turbo', size: '1.5GB', quality: 'Fast + Good', bundled: false },
    { id: 'large-v3', size: '3GB', quality: 'Best', bundled: false },
  ],
  llm: [
    { id: 'phi-3-mini', size: '2.2GB', quality: 'Fast', bundled: false },
    { id: 'llama-3.2-3b', size: '2GB', quality: 'Balanced', bundled: false },
    { id: 'mistral-7b', size: '4GB', quality: 'Quality', bundled: false },
  ],
  diarization: [
    { id: 'pyannote-3.1', size: '50MB', quality: 'Standard', bundled: true },
  ]
};
```

### Build-time Pyannote Bundling

```bash
# Run with your HuggingFace token at build time
export HF_TOKEN="your-token-here"

python3 -c "
from pyannote.audio import Pipeline
pipeline = Pipeline.from_pretrained(
    'pyannote/speaker-diarization-3.1',
    use_auth_token='$HF_TOKEN'
)
import torch
torch.save(pipeline, 'build/models/pyannote/diarization-3.1.pt')
"
```

---

## First-Run Experience

### Setup Flow

```
Step 1: Welcome
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚                    ğŸ™ï¸ Verbatim Studio                       â”‚
â”‚                                                             â”‚
â”‚          Professional transcription, fully private          â”‚
â”‚                                                             â”‚
â”‚    Everything runs on your Mac. No cloud. No subscriptions. â”‚
â”‚                                                             â”‚
â”‚                      [Get Started â†’]                        â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 2: Storage Location
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚  Step 1 of 3 Â· Storage Location                             â”‚
â”‚                                                             â”‚
â”‚  Where should Verbatim store recordings and transcripts?    â”‚
â”‚                                                             â”‚
â”‚  â—‰ Default location                                         â”‚
â”‚    ~/Documents/Verbatim Studio                              â”‚
â”‚                                                             â”‚
â”‚  â—‹ Custom location                                          â”‚
â”‚    [Choose Folder...]                                       â”‚
â”‚                                                             â”‚
â”‚                           [Back]  [Continue â†’]              â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 3: Model Selection
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚  Step 2 of 3 Â· Transcription Quality                        â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â—‰ Large-v3 (Recommended)                      3.0 GB  â”‚ â”‚
â”‚  â”‚   Highest accuracy for legal, medical, professional   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â—‹ Turbo                                       1.5 GB  â”‚ â”‚
â”‚  â”‚   Great accuracy, faster processing                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â—‹ Base                                        142 MB  â”‚ â”‚
â”‚  â”‚   Good for quick notes, casual use                    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â—‹ Minimal                                     0 MB    â”‚ â”‚
â”‚  â”‚   Use bundled model, upgrade anytime in Settings      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                             â”‚
â”‚                           [Back]  [Download & Continue â†’]   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 4: Ready
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚  Step 3 of 3 Â· Ready!                                       â”‚
â”‚                                                             â”‚
â”‚                          âœ“                                  â”‚
â”‚                                                             â”‚
â”‚  Verbatim Studio is ready to use.                           â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ âœ“ Transcription engine           whisper-large-v3     â”‚ â”‚
â”‚  â”‚ âœ“ Speaker identification         pyannote-3.1         â”‚ â”‚
â”‚  â”‚ â—‹ AI Summarization               Not installed        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                             â”‚
â”‚  ğŸ’¡ AI features like summarization and chat can be added    â”‚
â”‚     anytime from Settings â†’ AI Models                       â”‚
â”‚                                                             â”‚
â”‚                              [Open Verbatim Studio â†’]       â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Configuration File

```json
// ~/Library/Application Support/Verbatim Studio/config.json
{
  "version": 1,
  "setupComplete": true,
  "storagePath": "~/Documents/Verbatim Studio",
  "models": {
    "whisper": "large-v3",
    "diarization": "pyannote-3.1",
    "llm": null
  },
  "preferences": {
    "theme": "system",
    "defaultExportFormat": "docx"
  }
}
```

---

## Build & Packaging Pipeline

### Source Directory Structure

```
verbatim-studio/
â”œâ”€â”€ apps/
â”‚   â””â”€â”€ electron/
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ main/           # Electron main process
â”‚       â”‚   â””â”€â”€ preload/        # Context bridge
â”‚       â”œâ”€â”€ electron-builder.yml
â”‚       â””â”€â”€ package.json
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ frontend/               # React app
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ package.json
â”‚   â””â”€â”€ backend/                # FastAPI (Python)
â”‚       â”œâ”€â”€ api/
â”‚       â”œâ”€â”€ services/
â”‚       â””â”€â”€ pyproject.toml
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build-macos.sh          # Full build script
â”‚   â”œâ”€â”€ bundle-python.sh        # Python runtime bundler
â”‚   â”œâ”€â”€ bundle-binaries.sh      # whisper.cpp, llama.cpp
â”‚   â””â”€â”€ bundle-models.sh        # Bundled models
â””â”€â”€ package.json                # Monorepo root (pnpm workspaces)
```

### Build Script

```bash
#!/bin/bash
# scripts/build-macos.sh

set -e

BUILD_DIR="build/macos-arm64"
RESOURCES_DIR="$BUILD_DIR/resources"

echo "=== Building Verbatim Studio for macOS ARM64 ==="

# 1. Clean
rm -rf $BUILD_DIR
mkdir -p $RESOURCES_DIR

# 2. Build frontend
echo "Building frontend..."
cd packages/frontend
pnpm build
cp -r dist $RESOURCES_DIR/renderer
cd ../..

# 3. Bundle Python runtime + backend
echo "Bundling Python..."
./scripts/bundle-python.sh $RESOURCES_DIR/python

# 4. Compile native binaries
echo "Building whisper.cpp..."
git clone --depth 1 https://github.com/ggerganov/whisper.cpp /tmp/whisper.cpp
cd /tmp/whisper.cpp
make -j clean
WHISPER_METAL=1 make -j server
cp server $RESOURCES_DIR/bin/whisper-server
cd -

echo "Building llama.cpp..."
git clone --depth 1 https://github.com/ggerganov/llama.cpp /tmp/llama.cpp
cd /tmp/llama.cpp
make -j clean
LLAMA_METAL=1 make -j server
cp server $RESOURCES_DIR/bin/llama-server
cd -

# 5. Bundle models
echo "Bundling models..."
./scripts/bundle-models.sh $RESOURCES_DIR/models

# 6. Build Electron app
echo "Packaging Electron..."
cd apps/electron
pnpm electron-builder --mac --arm64 \
  --config.directories.buildResources=../../$RESOURCES_DIR
cd ../..

echo "=== Build complete: dist/Verbatim Studio.dmg ==="
```

### electron-builder.yml

```yaml
appId: com.verbatimstudio.app
productName: Verbatim Studio

directories:
  output: ../../dist

mac:
  category: public.app-category.productivity
  target:
    - target: dmg
      arch: arm64
  icon: resources/icon.icns
  hardenedRuntime: true
  gatekeeperAssess: false
  entitlements: entitlements.mac.plist
  entitlementsInherit: entitlements.mac.plist

extraResources:
  - from: "../../build/macos-arm64/resources"
    to: "."
    filter:
      - "**/*"

dmg:
  title: "Verbatim Studio"
  contents:
    - x: 130
      y: 220
    - x: 410
      y: 220
      type: link
      path: /Applications
```

### Entitlements

```xml
<!-- apps/electron/entitlements.mac.plist -->
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN"
  "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
    <key>com.apple.security.cs.allow-jit</key>
    <true/>
    <key>com.apple.security.cs.allow-unsigned-executable-memory</key>
    <true/>
    <key>com.apple.security.device.audio-input</key>
    <true/>
    <key>com.apple.security.cs.disable-library-validation</key>
    <true/>
</dict>
</plist>
```

### Final App Size

| Component | Size |
|-----------|------|
| Electron | ~150 MB |
| Python bundle | ~260 MB |
| whisper.cpp + llama.cpp binaries | ~5 MB |
| Bundled models (tiny + pyannote) | ~125 MB |
| Frontend | ~5 MB |
| **Total DMG** | **~550 MB** |

---

## Database Schema

```sql
-- Projects organize recordings
CREATE TABLE projects (
    id TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),
    name TEXT NOT NULL,
    description TEXT,
    template_id TEXT,
    metadata JSON DEFAULT '{}',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Recordings (audio/video files)
CREATE TABLE recordings (
    id TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),
    project_id TEXT REFERENCES projects(id) ON DELETE SET NULL,
    title TEXT NOT NULL,
    file_path TEXT NOT NULL,
    file_name TEXT NOT NULL,
    file_size INTEGER,
    duration_seconds REAL,
    mime_type TEXT,
    metadata JSON DEFAULT '{}',
    status TEXT DEFAULT 'pending',  -- pending, processing, completed, failed
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Transcripts linked to recordings
CREATE TABLE transcripts (
    id TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),
    recording_id TEXT NOT NULL REFERENCES recordings(id) ON DELETE CASCADE,
    language TEXT,
    model_used TEXT,
    confidence_avg REAL,
    word_count INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Individual segments (utterances with speaker + timing)
CREATE TABLE segments (
    id TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),
    transcript_id TEXT NOT NULL REFERENCES transcripts(id) ON DELETE CASCADE,
    segment_index INTEGER NOT NULL,
    speaker TEXT,                    -- "Speaker 1", "Speaker 2", or custom name
    start_time REAL NOT NULL,        -- seconds
    end_time REAL NOT NULL,
    text TEXT NOT NULL,
    confidence REAL,
    edited BOOLEAN DEFAULT FALSE,    -- user has modified
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
CREATE INDEX idx_segments_transcript ON segments(transcript_id, segment_index);

-- Speaker mappings (assign names to detected speakers)
CREATE TABLE speakers (
    id TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),
    transcript_id TEXT NOT NULL REFERENCES transcripts(id) ON DELETE CASCADE,
    speaker_label TEXT NOT NULL,     -- "Speaker 1"
    speaker_name TEXT,               -- "John Smith"
    color TEXT,                      -- UI display color
    UNIQUE(transcript_id, speaker_label)
);

-- AI-generated summaries
CREATE TABLE summaries (
    id TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),
    transcript_id TEXT NOT NULL REFERENCES transcripts(id) ON DELETE CASCADE,
    summary_type TEXT NOT NULL,      -- 'brief', 'detailed', 'bullets', 'action_items'
    content TEXT NOT NULL,
    model_used TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Export history
CREATE TABLE exports (
    id TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),
    transcript_id TEXT NOT NULL REFERENCES transcripts(id) ON DELETE CASCADE,
    format TEXT NOT NULL,            -- 'docx', 'pdf', 'srt', 'vtt', 'txt'
    file_path TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Job queue (replaces Celery for Basic mode)
CREATE TABLE jobs (
    id TEXT PRIMARY KEY DEFAULT (lower(hex(randomblob(16)))),
    job_type TEXT NOT NULL,          -- 'transcribe', 'diarize', 'summarize'
    status TEXT DEFAULT 'queued',    -- queued, running, completed, failed
    payload JSON NOT NULL,
    result JSON,
    error TEXT,
    progress REAL DEFAULT 0,         -- 0-100
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    started_at TIMESTAMP,
    completed_at TIMESTAMP
);
CREATE INDEX idx_jobs_status ON jobs(status, created_at);

-- App settings
CREATE TABLE settings (
    key TEXT PRIMARY KEY,
    value JSON NOT NULL,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

---

## API Structure

**Base URL**: `http://127.0.0.1:8000/api`

```
/api
â”œâ”€â”€ /health                    GET     Health check
â”œâ”€â”€ /config                    GET     App configuration
â”‚
â”œâ”€â”€ /projects
â”‚   â”œâ”€â”€ /                      GET     List projects
â”‚   â”œâ”€â”€ /                      POST    Create project
â”‚   â”œâ”€â”€ /{id}                  GET     Get project
â”‚   â”œâ”€â”€ /{id}                  PATCH   Update project
â”‚   â”œâ”€â”€ /{id}                  DELETE  Delete project
â”‚   â””â”€â”€ /{id}/recordings       GET     List recordings in project
â”‚
â”œâ”€â”€ /recordings
â”‚   â”œâ”€â”€ /                      GET     List all recordings
â”‚   â”œâ”€â”€ /upload                POST    Upload audio/video file
â”‚   â”œâ”€â”€ /{id}                  GET     Get recording details
â”‚   â”œâ”€â”€ /{id}                  PATCH   Update recording
â”‚   â”œâ”€â”€ /{id}                  DELETE  Delete recording
â”‚   â”œâ”€â”€ /{id}/transcribe       POST    Start transcription job
â”‚   â””â”€â”€ /{id}/stream           GET     Stream audio file
â”‚
â”œâ”€â”€ /transcripts
â”‚   â”œâ”€â”€ /{id}                  GET     Get full transcript
â”‚   â”œâ”€â”€ /{id}/segments         GET     Get segments (paginated)
â”‚   â”œâ”€â”€ /{id}/segments/{sid}   PATCH   Update segment text
â”‚   â”œâ”€â”€ /{id}/speakers         GET     Get speaker mappings
â”‚   â”œâ”€â”€ /{id}/speakers/{label} PATCH   Update speaker name
â”‚   â””â”€â”€ /{id}/export/{format}  GET     Export transcript
â”‚
â”œâ”€â”€ /ai
â”‚   â”œâ”€â”€ /summarize             POST    Generate summary
â”‚   â”œâ”€â”€ /chat                  POST    Chat about transcript
â”‚   â””â”€â”€ /search                POST    Semantic search
â”‚
â”œâ”€â”€ /jobs
â”‚   â”œâ”€â”€ /                      GET     List jobs
â”‚   â”œâ”€â”€ /{id}                  GET     Get job status
â”‚   â””â”€â”€ /{id}/cancel           POST    Cancel job
â”‚
â”œâ”€â”€ /models
â”‚   â”œâ”€â”€ /                      GET     List installed models
â”‚   â”œâ”€â”€ /available             GET     List downloadable models
â”‚   â”œâ”€â”€ /download              POST    Start model download
â”‚   â””â”€â”€ /download/{id}         DELETE  Cancel download
â”‚
â””â”€â”€ /ws
    â”œâ”€â”€ /transcribe            WS      Real-time transcription
    â””â”€â”€ /jobs/{id}             WS      Job progress updates
```

---

## Frontend Structure

```
packages/frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ App.tsx                 # Root component, routing
â”‚   â”‚   â”œâ”€â”€ Layout.tsx              # Main app shell
â”‚   â”‚   â””â”€â”€ providers.tsx           # React Query, Theme
â”‚   â”‚
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ setup/
â”‚   â”‚   â”‚   â”œâ”€â”€ WelcomePage.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ StoragePage.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ModelsPage.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ReadyPage.tsx
â”‚   â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â”‚   â””â”€â”€ DashboardPage.tsx
â”‚   â”‚   â”œâ”€â”€ recordings/
â”‚   â”‚   â”‚   â”œâ”€â”€ RecordingsPage.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ UploadPage.tsx
â”‚   â”‚   â”‚   â””â”€â”€ RecordPage.tsx
â”‚   â”‚   â”œâ”€â”€ transcript/
â”‚   â”‚   â”‚   â””â”€â”€ TranscriptPage.tsx
â”‚   â”‚   â”œâ”€â”€ projects/
â”‚   â”‚   â”‚   â”œâ”€â”€ ProjectsPage.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ProjectPage.tsx
â”‚   â”‚   â””â”€â”€ settings/
â”‚   â”‚       â”œâ”€â”€ SettingsPage.tsx
â”‚   â”‚       â”œâ”€â”€ ModelsSettings.tsx
â”‚   â”‚       â””â”€â”€ GeneralSettings.tsx
â”‚   â”‚
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ui/                     # shadcn/ui components
â”‚   â”‚   â”œâ”€â”€ transcript/
â”‚   â”‚   â”‚   â”œâ”€â”€ TranscriptEditor.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ SegmentRow.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ SpeakerBadge.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Waveform.tsx
â”‚   â”‚   â”‚   â””â”€â”€ TimeCode.tsx
â”‚   â”‚   â”œâ”€â”€ recording/
â”‚   â”‚   â”‚   â”œâ”€â”€ AudioPlayer.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ RecordingCard.tsx
â”‚   â”‚   â”‚   â””â”€â”€ LiveRecorder.tsx
â”‚   â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”‚   â”œâ”€â”€ SummaryPanel.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatPanel.tsx
â”‚   â”‚   â”‚   â””â”€â”€ SearchResults.tsx
â”‚   â”‚   â””â”€â”€ layout/
â”‚   â”‚       â”œâ”€â”€ Sidebar.tsx
â”‚   â”‚       â”œâ”€â”€ Header.tsx
â”‚   â”‚       â””â”€â”€ JobsIndicator.tsx
â”‚   â”‚
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ api.ts
â”‚   â”‚   â”œâ”€â”€ electron.ts
â”‚   â”‚   â”œâ”€â”€ audio.ts
â”‚   â”‚   â””â”€â”€ utils.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”œâ”€â”€ useRecording.ts
â”‚   â”‚   â”œâ”€â”€ useTranscript.ts
â”‚   â”‚   â”œâ”€â”€ useJobs.ts
â”‚   â”‚   â””â”€â”€ useModels.ts
â”‚   â”‚
â”‚   â””â”€â”€ types/
â”‚       â””â”€â”€ index.ts
â”‚
â”œâ”€â”€ index.html
â”œâ”€â”€ vite.config.ts
â”œâ”€â”€ tailwind.config.ts
â””â”€â”€ package.json
```

---

## Path to Enterprise

### What Changes

| Component | Basic Mode | Enterprise Mode |
|-----------|------------|-----------------|
| Database | SQLite (local file) | PostgreSQL (server) |
| Job Queue | ThreadPoolExecutor | Celery + Redis |
| Auth | None (implicit user) | JWT + RBAC |
| Backend | Electron subprocess | Docker container(s) |
| Frontend | Electron renderer | Browser + Electron thin client |
| Models | User machine | Centralized server |
| Storage | Local filesystem | S3-compatible / NFS |

### Abstraction for Both Modes

```python
# packages/backend/core/config.py

class Settings(BaseSettings):
    MODE: Literal["basic", "enterprise"] = "basic"
    DATABASE_URL: str = "sqlite:///./verbatim.db"
    AUTH_ENABLED: bool = False
    CELERY_BROKER_URL: str | None = None

    @property
    def use_celery(self) -> bool:
        return self.MODE == "enterprise" and self.CELERY_BROKER_URL
```

```python
# packages/backend/services/jobs.py

class JobQueue:
    @classmethod
    async def enqueue(cls, job_type: str, payload: dict) -> Job:
        settings = get_settings()

        if settings.use_celery:
            from .celery_tasks import run_job
            task = run_job.delay(job_type, payload)
            return Job(id=task.id, status="queued", ...)
        else:
            job = await Job.create(job_type=job_type, payload=payload)
            executor.submit(run_job_sync, job.id)
            return job
```

---

## Implementation Phases

### Phase 1: Foundation
- Monorepo setup (pnpm workspaces)
- Electron shell with basic window
- FastAPI skeleton with health check
- SQLite database + migrations
- Python bundling script (proof of concept)

### Phase 2: Core Transcription
- File upload + storage
- whisper.cpp integration (batch mode first)
- Basic transcript viewer (read-only)
- Jobs queue (ThreadPoolExecutor)

### Phase 3: Speaker Diarization
- Pyannote integration
- Speaker assignment to segments
- Speaker renaming UI

### Phase 4: Transcript Editor
- Segment editing
- Audio player with sync
- Waveform visualization
- Keyboard navigation

### Phase 5: Real-Time Transcription
- Microphone capture
- WebSocket streaming
- whisper.cpp streaming mode
- Live transcript display

### Phase 6: AI Features
- llama.cpp integration
- Summarization
- Chat interface
- Semantic search (embeddings)

### Phase 7: Polish & Export
- Export formats (DOCX, PDF, SRT, VTT)
- Projects & organization
- Settings UI
- Model management UI

### Phase 8: Build & Distribution
- Full build pipeline
- Code signing
- DMG creation
- Auto-updater

---

## Appendix: Future Platform Support

### Windows (Future)
- CUDA support for NVIDIA GPUs
- NSIS installer instead of DMG
- Windows-specific entitlements

### Linux (Future)
- AppImage or Flatpak distribution
- CUDA for NVIDIA, ROCm for AMD
- PulseAudio/PipeWire for audio capture

### Architecture
The design supports cross-platform by:
1. Native binary compilation per platform (whisper.cpp, llama.cpp)
2. Platform-specific Python bundles (python-build-standalone)
3. Electron's cross-platform capabilities
4. Abstract file paths and OS-specific code in Electron main process
